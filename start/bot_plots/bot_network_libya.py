# -*- coding: utf-8 -*-
"""Bot Network Libya.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10yrjPvRgqkdC7HBXQmRzrlGsvt7R9f3N
"""

from datetime import datetime, timedelta
import numpy as np
import networkx as nx
from networkx.algorithms import community

import sqlite3,sys,os,string
import pandas as pd
import matplotlib.pyplot as plt


from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
from create_retweet_graph import *
#from helper_follower_network_crawler import *
#from SpectralCommunities import spectral_clustering
from collections import Counter

import scipy.sparse
import sklearn.datasets
import sklearn.feature_extraction.text
import umap
import umap.plot
import holoviews as hv
from holoviews import opts
from bokeh.plotting  import show
from bokeh.models import HoverTool
hv.extension('bokeh')

defaults = dict(width=600, height=600)
hv.opts.defaults(
    opts.EdgePaths(**defaults), opts.Graph(**defaults), opts.Nodes(**defaults))

#Load follower network and user info
path = 'C://Users//Zlisto//Dropbox (Personal)//MIDAC//Libya//Libya//Data//'
fname_tweets = path+"All_Arabic.db"
fname_follower_graph  = path+"FollowerNetworkLibyaAll_UsersGbot.gpickle"
fname_retweet_graph  = path+"RetweetNetworkLibyaArabic.gpickle"
fname_users = path+"nodes_All_Users.csv"
conn = sqlite3.connect("%s"%fname_tweets)
#load tweets into dataframe
df_tweets = pd.read_sql_query("SELECT * FROM tweet", conn)
df_users = pd.read_csv(fname_users)

print(df_tweets.describe())
print(df_users.describe())

#Gretweet = retweet_network_from_tweets(df_tweets)
#nx.write_gpickle(Gretweet, path+"RetweetNetworkLibyaArabic.gpickle")
Gretweet = nx.read_gpickle(fname_retweet_graph)

#Pull the bots and those the bots retweet
Bots = list(df_users.id[df_users.Bot==1].values)
RetweetSources = []
for v in Gretweet.nodes():
    if v in Bots:
        RetweetSources+= Gretweet.predecessors(v)
RetweetSourceCounter = Counter(RetweetSources)
dmin = 100
RetweetSources = list([v for v in RetweetSourceCounter.keys() if RetweetSourceCounter[v]>=dmin])
print(RetweetSourceCounter.most_common(10))
print("%s bots retweet %s sources"%(len(Bots),len(RetweetSources)))

len(Bots+RetweetSources)

Gfollower = nx.read_gpickle(fname_follower_graph)
print("Loaded follower graph with %s nodes"%(Gfollower.number_of_nodes()))

# Commented out IPython magic to ensure Python compatibility.
#draw following network of bots and their following
#first get coordinates for the bots
G = Gfollower.subgraph(Bots).copy()
A = nx.adjacency_matrix(G)
min_dist = 1
n_neighbors = 25
fit = umap.UMAP(metric='cosine',min_dist=min_dist,n_neighbors=n_neighbors)
# %time utransform = fit.fit_transform(A)
coords_bots =  utransform-utransform.mean(axis=0, keepdims=True)

plt.scatter(coords_bots[:,0],coords_bots[:,1], c=np.arange(A.shape[0]))
plt.grid()
plt.title("Bots")
plt.show()

NodeCoords = {}
for cnt,v in enumerate(G.nodes()):
    NodeCoords[v] = coords_bots[cnt,:]

# Commented out IPython magic to ensure Python compatibility.
#draw following network of bots and their following
#first get coordinates for the bots
G = Gfollower.subgraph(RetweetSources).copy()
A = nx.adjacency_matrix(G)
min_dist = 1
n_neighbors = 25
fit = umap.UMAP(metric='cosine',min_dist=min_dist,n_neighbors=n_neighbors)
# %time utransform = fit.fit_transform(A)
xshift = 0
yshift = np.max(coords_bots,axis=0, keepdims=True)[0,1]
shift = np.array([xshift,yshift])
coords_sources = utransform - utransform.mean(axis=0, keepdims=True)+ shift

xshift = 0
yshift = 10
coords_sources = coords_sources + np.array([xshift,yshift])
plt.scatter(coords_sources[:,0],coords_sources[:,1], c=np.arange(A.shape[0]))
plt.grid()
plt.title("Sources")
plt.show()

for cnt,v in enumerate(G.nodes()):
    NodeCoords[v] = coords_sources[cnt,:]

np.max([G.out_degree(v) for v in G.nodes()]),np.mean([G.out_degree(v) for v in G.nodes()])

G = Gfollower.subgraph(Bots+RetweetSources).copy()
nv = G.number_of_nodes()
ne = G.number_of_edges()
print("Network of bots and their retweet sources has %s nodes and %s edges"%(nv,ne))

pos = {}
for cnt,v in enumerate(G.nodes()):
    x = df_users[df_users.id==v]
    pos[v] = NodeCoords[v]
    
    G.nodes[v]['out_degree'] = str(G.out_degree(v))
    G.nodes[v]['in_degree'] = str(G.in_degree(v))
    G.nodes[v]["node_size"] = G.out_degree(v)/100+3
    G.nodes[v]['screen_name'] = x.id.values[0]
    G.nodes[v]['bot'] = x.Bot.values[0]

    opinion = x.InitialOpinion.values[0]
    G.nodes[v]["opinion"] = opinion
    G.nodes[v]['node_color'] = opinion
    if cnt%1000==0:print("Node %s"%cnt)
print("Node properties calculated")

for cnt,e in enumerate(G.edges()):
    w = 0.5
    G.edges[e[0],e[1]]['Weight'] = w

tooltips = [
    ('Screen name','@screen_name'),
    #('Out-degree', '@out_degree'),
    #('In-degree', '@in_degree'),
    ('Bot', '@bot'),
    ("Opinion","@opinion")
    
]
hover = HoverTool(tooltips=tooltips)
graph = hv.Graph.from_networkx(G, pos).opts(height=600, width=600, tools=[hover],node_size =hv.dim("node_size"), 
                                     edge_line_color = 'purple',bgcolor='black',
                                    node_hover_fill_color = 'red',color_index='node_color', cmap='seismic',
                                    edge_line_width=.01
                                           ).relabel("Libyan Civil War")
#Holoviews colormaps http://holoviews.org/user_guide/Colormaps.html
graph

